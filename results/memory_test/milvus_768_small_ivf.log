Profiling: Insertion
Insertion Time: 105.10413670539856
Number of entities in Milvus: 100000
Filename: /ssddata/zchenhj/vectorDB_study/milvus_mem.py

base_data_path = '/ssddata/vecDB_publi_data/test_data_0919/wikisum_bert-nli-mean_base_small.npy'
base_data_size = 293M

query_data_path = '/ssddata/vecDB_publi_data/test_data_0919/wikisum_bert-nli-mean_query_large.npy'
query_data_size = 6MB (Only 2,000 points are selected)


Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    80    432.2 MiB    432.2 MiB           1       @profile
    81                                             def insert_entitiy(self, batch_size=0):
    82                                                 
    83    432.2 MiB      0.0 MiB           1           assert self.collection is not None
    84                                                 
    85    436.0 MiB      0.0 MiB           2           def _batch_insert(collection, entities, batch_size):
    86    436.0 MiB      0.0 MiB           1               num_entities = len(entities[0])
    87    577.1 MiB     -0.5 MiB           6               for i in tqdm(range(0, int(num_entities / batch_size) + 1)):    
    88    577.1 MiB     -0.7 MiB           6                   start_idx = i * batch_size
    89    577.1 MiB     -0.7 MiB           6                   end_index = min((i + 1) * batch_size, num_entities)
    90    577.1 MiB     -0.7 MiB           6                   if start_idx == end_index:
    91    576.9 MiB     -0.2 MiB           1                       break
    92    576.6 MiB     -0.4 MiB           5                   batch = [entities[0][start_idx:end_index], entities[1][start_idx:end_index]]
    93    577.1 MiB    140.0 MiB           5                   collection.insert(batch)
    94                                         
    95    436.0 MiB      0.0 MiB           1           entities = [
    96    436.0 MiB      3.8 MiB      100003               [int(i) for i in range(self.num_entities)], 
    97    436.0 MiB      0.0 MiB           1               self.data
    98                                                 ]
    99                                                 
   100    436.0 MiB      0.0 MiB           1           if batch_size == 0:
   101                                                     _ = self.collection.insert(entities)
   102                                                 else:
   103    436.0 MiB      0.0 MiB           1               start_insert_time = time.time()
   104    576.9 MiB      0.0 MiB           1               _batch_insert(self.collection, entities, batch_size)
   105    576.9 MiB      0.0 MiB           1               end_insert_time = time.time()
   106    576.9 MiB      0.0 MiB           1               print(f"Insertion Time: {end_insert_time - start_insert_time}")
   107    576.9 MiB      0.0 MiB           1               self.collection.flush()
   108    576.9 MiB      0.0 MiB           1               print(f"Number of entities in Milvus: {self.collection.num_entities}")


Profiling: Index Creation
Index Time: 16.70805525779724
Filename: /ssddata/zchenhj/vectorDB_study/milvus_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   111    573.1 MiB    573.1 MiB           1       @profile
   112                                             def create_index(self, indexType: str):
   113                                                 
   114    573.1 MiB      0.0 MiB           1           assert indexType in config_index_param
   115    573.1 MiB      0.0 MiB                      self.indexType = indexType
   116                                                 
   117    573.1 MiB      0.0 MiB           1           index = {
   118    573.1 MiB      0.0 MiB           1               "index_type": indexType,
   119    573.1 MiB      0.0 MiB           1               "metric_type": "L2",
   120    573.1 MiB      0.0 MiB           1               "params": config_index_param[indexType],
   121                                                 }
   122    573.1 MiB      0.0 MiB           1           self.collection.drop_index()
   123    573.1 MiB      0.0 MiB           1           start_create_index = time.time()
   124    573.1 MiB      0.0 MiB           1           self.collection.create_index(self.data_name, index)
   125    573.1 MiB      0.0 MiB           1           end_create_index = time.time()
   126    573.1 MiB      0.0 MiB           1           self.time_create_index = end_create_index - start_create_index
   127    573.1 MiB      0.0 MiB           1           print(f"Index Time: {end_create_index - start_create_index}")


Profiling: ANN Search
Query Time: 8.906005144119263
Filename: /ssddata/zchenhj/vectorDB_study/milvus_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   130    573.1 MiB    573.1 MiB           1       @profile
   131                                             def topk_anns(self, top_k: int, metricType: str):
   132                                                 
   133    573.1 MiB      0.0 MiB           1           self.collection.load()
   134    573.1 MiB      0.0 MiB           1           self.top_k = top_k
   135    573.1 MiB      0.0 MiB           1           self.metric = metricType
   136                                                 
   137    573.1 MiB      0.0 MiB           1           search_params = {
   138    573.1 MiB      0.0 MiB           1               "metric_type": metricType,
   139    573.1 MiB      0.0 MiB           1               "params": config_search_param[self.indexType],
   140                                                 }
   141                                                 
   142    573.1 MiB      0.0 MiB           1           query_start_time = time.time()
   143    626.4 MiB     53.3 MiB           1           result = self.collection.search(self.vectors_to_search, self.data_name, search_params, limit=top_k)
   144    626.4 MiB      0.0 MiB           1           query_end_time = time.time()
   145    626.4 MiB      0.0 MiB           1           self.time_query = query_end_time - query_start_time
   146    626.4 MiB      0.0 MiB           1           print(f"Query Time: {self.time_query}")
   147                                                 
   148    626.4 MiB      0.0 MiB           1           self.anns_result = []
   149    627.0 MiB      0.0 MiB        2001           for hits in result:
   150    627.0 MiB      0.2 MiB        2000               curr_result = set() # top-k neighbour of the current query point
   151    627.0 MiB      0.0 MiB      202000               for hit in hits:
   152    627.0 MiB      0.3 MiB      200000                   curr_result.add(int(hit.id))
   153    627.0 MiB      0.0 MiB        2000               self.anns_result.append(curr_result)


